{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "229551b6",
      "metadata": {},
      "source": [
        "# Dog Emotion Classifier\n",
        "This notebook trains a convolutional model on dog emotion images stored in the root `images/` folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "137aa315",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using h:\\DogEmotionn\\images with 15921 files\n",
            "Training on device: cuda\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets\n",
        "\n",
        "from dog_emotion_model import build_transforms, create_model\n",
        "\n",
        "DATASET_DIR = Path.cwd() / \"images\"\n",
        "MODEL_DIR = Path.cwd() / \"models\"\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "MODEL_PATH = MODEL_DIR / \"dog_emotion_cnn.pth\"\n",
        "METADATA_PATH = MODEL_DIR / \"metadata.json\"\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "VAL_SPLIT = 0.2\n",
        "IMAGE_SIZE = (224, 224)\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 12\n",
        "RNG_SEED = 42\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(RNG_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RNG_SEED)\n",
        "\n",
        "assert DATASET_DIR.exists(), f\"Dataset folder not found: {DATASET_DIR}\"\n",
        "print(f\"Using {DATASET_DIR} with {len(list(DATASET_DIR.rglob('*.*')))} files\")\n",
        "print(f\"Training on device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0c274d65",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _build_subsets(dataset_root: Path):\n",
        "    train_dataset = datasets.ImageFolder(dataset_root, transform=build_transforms(IMAGE_SIZE, augment=True))\n",
        "    val_dataset = datasets.ImageFolder(dataset_root, transform=build_transforms(IMAGE_SIZE, augment=False))\n",
        "    total_items = len(train_dataset)\n",
        "    val_length = max(1, int(total_items * VAL_SPLIT)) if total_items > 1 else 1\n",
        "    generator = torch.Generator().manual_seed(RNG_SEED)\n",
        "    shuffled = torch.randperm(total_items, generator=generator)\n",
        "    val_indices = shuffled[:val_length].tolist()\n",
        "    train_indices = shuffled[val_length:].tolist()\n",
        "    if not train_indices:\n",
        "        train_indices = val_indices\n",
        "        val_indices = val_indices[:1]\n",
        "    return Subset(train_dataset, train_indices), Subset(val_dataset, val_indices), train_dataset.classes\n",
        "\n",
        "\n",
        "def create_data_loaders(dataset_root: Path):\n",
        "    train_subset, val_subset, class_names = _build_subsets(dataset_root)\n",
        "    loader_kwargs = {\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'num_workers': 2,\n",
        "        'pin_memory': torch.cuda.is_available(),\n",
        "    }\n",
        "    train_loader = DataLoader(train_subset, shuffle=True, **loader_kwargs)\n",
        "    val_loader = DataLoader(val_subset, shuffle=False, **loader_kwargs)\n",
        "    return train_loader, val_loader, class_names\n",
        "\n",
        "\n",
        "def save_metadata(class_names):\n",
        "    metadata = {\n",
        "        \"class_names\": class_names,\n",
        "        \"image_size\": IMAGE_SIZE,\n",
        "        \"model_path\": str(MODEL_PATH.relative_to(Path.cwd())),\n",
        "        \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    }\n",
        "    METADATA_PATH.write_text(json.dumps(metadata, indent=2))\n",
        "    return metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b4b98e38",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(model: nn.Module, data_loader: DataLoader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in data_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        predictions = outputs.argmax(dim=1)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module, data_loader: DataLoader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predictions = outputs.argmax(dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def fit(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    best_val_accuracy = 0.0\n",
        "    best_state = None\n",
        "    history = []\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
        "        history.append({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_acc\": val_acc,\n",
        "        })\n",
        "        print(f\"Epoch {epoch}/{EPOCHS} - train_loss: {train_loss:.4f} train_acc: {train_acc:.3f} val_loss: {val_loss:.4f} val_acc: {val_acc:.3f}\")\n",
        "        if val_acc > best_val_accuracy:\n",
        "            best_val_accuracy = val_acc\n",
        "            best_state = model.state_dict()\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1f134651",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\17619/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:12<00:00, 43.5MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12 - train_loss: 1.6584 train_acc: 0.343 val_loss: 1.2940 val_acc: 0.413\n",
            "Epoch 2/12 - train_loss: 1.5877 train_acc: 0.338 val_loss: 1.3300 val_acc: 0.399\n",
            "Epoch 3/12 - train_loss: 1.4385 train_acc: 0.365 val_loss: 1.2969 val_acc: 0.430\n",
            "Epoch 4/12 - train_loss: 1.4332 train_acc: 0.368 val_loss: 1.3057 val_acc: 0.404\n",
            "Epoch 5/12 - train_loss: 1.3914 train_acc: 0.377 val_loss: 1.2783 val_acc: 0.467\n",
            "Epoch 6/12 - train_loss: 1.3820 train_acc: 0.384 val_loss: 1.2554 val_acc: 0.453\n",
            "Epoch 7/12 - train_loss: 1.3722 train_acc: 0.390 val_loss: 1.2738 val_acc: 0.445\n",
            "Epoch 8/12 - train_loss: 1.3690 train_acc: 0.396 val_loss: 1.2730 val_acc: 0.408\n",
            "Epoch 9/12 - train_loss: 1.3594 train_acc: 0.390 val_loss: 1.2509 val_acc: 0.448\n",
            "Epoch 10/12 - train_loss: 1.3523 train_acc: 0.395 val_loss: 1.2749 val_acc: 0.421\n",
            "Epoch 11/12 - train_loss: 1.3477 train_acc: 0.396 val_loss: 1.2525 val_acc: 0.445\n",
            "Epoch 12/12 - train_loss: 1.3442 train_acc: 0.388 val_loss: 1.2462 val_acc: 0.451\n",
            "Model saved to h:\\DogEmotionn\\models\\dog_emotion_cnn.pth\n",
            "Metadata saved to h:\\DogEmotionn\\models\\metadata.json\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, class_names = create_data_loaders(DATASET_DIR)\n",
        "model = create_model(num_classes=len(class_names)).to(DEVICE)\n",
        "training_history = fit(model, train_loader, val_loader)\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "metadata = save_metadata(class_names)\n",
        "print(f\"Model saved to {MODEL_PATH}\")\n",
        "print(f\"Metadata saved to {METADATA_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "58847190",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\17619\\AppData\\Local\\Temp\\ipykernel_28704\\2239903890.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  reloaded_model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction 1: sad (33.53%)\n",
            "Prediction 2: happy (31.06%)\n",
            "Prediction 3: sad (36.31%)\n",
            "Prediction 4: happy (28.55%)\n",
            "Prediction 5: happy (33.47%)\n"
          ]
        }
      ],
      "source": [
        "reloaded_model = create_model(num_classes=len(class_names)).to(DEVICE)\n",
        "reloaded_model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "reloaded_model.eval()\n",
        "sample_inputs, _ = next(iter(val_loader))\n",
        "with torch.no_grad():\n",
        "    probabilities = torch.softmax(reloaded_model(sample_inputs.to(DEVICE)), dim=1)\n",
        "    scores, indices = torch.max(probabilities, dim=1)\n",
        "for idx in range(min(5, sample_inputs.size(0))):\n",
        "    label = class_names[indices[idx].item()]\n",
        "    confidence = scores[idx].item()\n",
        "    print(f\"Prediction {idx + 1}: {label} ({confidence:.2%})\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
